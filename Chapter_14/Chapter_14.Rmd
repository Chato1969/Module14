---
title: "Module_14"
author: "Wesley Newcomb"
date: "2023-04-23"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
install.packages(c("httr", "jsonlite", "dplyr"))
library(httr)
library(jsonlite)
library(dplyr)
```


```{r exercixe_1, echo=TRUE, eval=TRUE}
# Exercise 1: reading and querying a web API

# Load the httr and jsonlite libraries for accessing data
# You can also load `dplyr` if you wish to use it
# Load libraries
#library(httr)
#library(jsonlite)
#library(dplyr)

# Create a variable base_uri that stores the base URI (as a string) for the 
# Github API (https://api.github.com)
# Set base URI for Github API
base_uri <- "https://api.github.com"

# Under the "Repositories" category of the API documentation, find the endpoint 
# that will list _repos in an organization_. Then create a variable named
# `org_resource` that stores the endpoint for the `programming-for-data-science`
# organization repos (this is the _path_ to the resource of interest).
# Set endpoint for programming-for-data-science organization repos
org_resource <- "/orgs/programming-for-data-science/repos"

# Send a GET request to this endpoint (the `base_uri` followed by the 
# `org_resource` path). Print the response to show that your request worked. 
# (The listed URI will also allow you to inspect the JSON in the browser easily).
# Send GET request to endpoint and print response
response <- GET(paste0(base_uri, org_resource))
print(response)

# Extract the content of the response using the `content()` function, saving it
# in a variable.
# Extract content of response and convert from JSON to data frame
content <- content(response, as = "text", encoding = "UTF-8")


# Convert the content variable from a JSON string into a data frame.
data <- fromJSON(content)

# How many (public) repositories does the organization have?
# Compute number of public repositories in organization
num_repos <- nrow(data)

# Now a second query:
# Create a variable `search_endpoint` that stores the endpoint used to search 
# for repositories. (Hint: look for a "Search" endpoint in the documentation).
# Set endpoint for searching repositories
search_endpoint <- "/search/repositories"

# Search queries require a query parameter (for what to search for). Create a 
# `query_params` list variable that specifies an appropriate key and value for 
# the search term (you can search for anything you want!)
# Set query parameters for search
query_params <- list(q = "data science")

# Send a GET request to the `search_endpoint`--including your params list as the
# `query`. Print the response to show that your request worked.
# Send GET request to search endpoint with query parameters and print response
response <- GET(paste0(base_uri, search_endpoint), query = query_params)
print(response)

# Extract the content of the response and convert it from a JSON string into a
# data frame. 
# Extract content of response and convert from JSON to data frame
content <- content(response, as = "text", encoding = "UTF-8")
data <- fromJSON(content)

# How many search repos did your search find? (Hint: check the list names to 
# find an appropriate value).
# Compute number of search results
num_results <- data$total_count

# What are the full names of the top 5 repos in the search results?
# Get full names of top 5 repos in search results
top_5_repos <- data$items %>% head(5) %>% select(full_name)
```


```{r load=api_key.R, exercise_2, echo=FALSE}
# Exercise 2: working with data APIs

# load relevant libraries
library("httr")
library("jsonlite")

# Be sure and check the README.md for complete instructions!


# Use `source()` to load your API key variable from the `apikey.R` file you made.
# Make sure you've set your working directory!
# Load API key from apikey.R file
# apikey.R
#apikey <- "apikey.R"
source("api_key.R")

# Create a variable `movie_name` that is the name of a movie of your choice.
movie_name <- "The Matrix"

# Construct an HTTP request to search for reviews for the given movie.
# The base URI is `https://api.nytimes.com/svc/movies/v2/`
# The resource is `reviews/search.json`
# See the interactive console for parameter details:
#   https://developer.nytimes.com/movie_reviews_v2.json
#
# You should use YOUR api key (as the `api-key` parameter)
# and your `movie_name` variable as the search query!
# Set movie name
movie_name <- "The Matrix"

# Send the HTTP Request to download the data
# Extract the content and convert it from JSON
# Construct HTTP request
base_uri <- "https://api.nytimes.com/svc/movies/v2/"
resource <- "reviews/search.json"
query <- paste0("query=", movie_name)
api_key_param <- paste0("api-key=", api_key)
request_uri <- paste0(base_uri, resource, "?", query, "&", api_key_param)

# What kind of data structure did this produce? A data frame? A list?
# Send HTTP request and extract content
response <- httr::GET(request_uri)
content <- httr::content(response, as = "text", encoding = "UTF-8")
data <- jsonlite::fromJSON(content)

# Manually inspect the returned data and identify the content of interest 
# (which are the movie reviews).
# Use functions such as `names()`, `str()`, etc.
# Inspect data structure
class(data)
names(data)
str(data)

# Flatten the movie reviews content into a data structure called `reviews`
# Flatten movie reviews content
reviews <- data$results

# From the most recent review, store the headline, short summary, and link to
# the full article, each in their own variables
# Store information from most recent review
headline <- reviews[[1]]$headline
summary <- reviews[[1]]$summary_short
link <- reviews[[1]]$link$url

# Create a list of the three pieces of information from above. 
# Print out the list.
# Create list of information and print it
review_info <- list(headline = headline, summary = summary, link = link)
print(review_info)


```


